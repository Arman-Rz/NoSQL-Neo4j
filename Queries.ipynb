{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5593c8fa-c616-4f13-a65f-eca5ab502f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "random.seed(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4a77c-726c-4b22-86c3-13ba5444704c",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Before we start, we need to define a function for running queries on the database. The function that Neo4j uses for this purpose is execute_query().  This function takes 3 inputs which are the query as a string, one or a list of parameters and the name of the database. In return, it gives three outputs which are records, summary and keys. Since we only need the records for this project, we define the following function in order to keep the code cleaner and easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a09db-139a-4489-9abb-3617795f3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query, parameters=None):\n",
    "    records, summary, keys = driver.execute_query(query, parameters,database_=\"neo4j\")\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394aa950-862c-473a-a259-5e28572926b7",
   "metadata": {},
   "source": [
    "# Starting the database\n",
    "To start the database, we need to run the following command into the CMD:  \n",
    "```\n",
    ">>start ... Path to Neo4j directory ...\\bin\\neo4j.bat console\n",
    "```\n",
    "This will start the database and also gives us a port to open the Neo4j browser which gives us access to the database.  \n",
    "However, since we want to have every operations automatic, we can run the following code. We use the function Popen() from the subprocess library. Unlike the run() that we used for importing data to the database, Popen() will run the command in the background, meaning we can continue with the rest of our code, while if we use run() we cannot continue unless we close stop the process which leads to stopping the database. Therefore, we should use Popen() that allows us to start the database in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2452899-bc11-4766-a469-f3a207239ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r\"... Path to Neo4j directory ...\"\n",
    "bot = rf\"{root}\\bin\\neo4j.bat\"\n",
    "command = f'start \"\" \"{bot}\" console'\n",
    "\n",
    "result = subprocess.Popen(command, cwd=f\"{root}\\\\bin\", shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d3806-d73d-47b4-a8c0-b178b74b0fd5",
   "metadata": {},
   "source": [
    "<br>\n",
    "When the database is running, we have to make a bridge between our python script and the database. We do this by calling the driver() from GraphDatabase library. This function takes the URI and Authentication data to connect to the database. The authentication is a tuple of username and password that is set for the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450bf9f-13ed-489d-bc97-3ebf0290ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = \"neo4j://127.0.0.1:7689\"\n",
    "AUTH = (\"neo4j\", \"Your Password\")\n",
    "\n",
    "driver =  GraphDatabase.driver(URI, auth=AUTH)\n",
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612f02e-8489-47bb-ac1d-74816aa22206",
   "metadata": {},
   "source": [
    "# Re-converting propertie's data types:\n",
    "Using the Admin tool to import data to the database comes with its own chalanges, Some of which we saw in the LoadDatabase file. The final chalange is when we start the database, we can see that the types of the data have been changed to a string with the value of \"null\". Therefore, we need to fix this issue before we can start querying the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069bb11b-fecc-417e-9be3-d622cd2e0fb7",
   "metadata": {},
   "source": [
    "## Customers\n",
    "Starting with the Customer nodes, the solution is easy for almost every properties. We set the type of the CUSTOMER_ID and nb_terminals to Integer, and others to Float, by simply using toInteger() and toFloat() functions.\n",
    "The only chalanging part is the available_terminals property, which is suppose to be a list of terminal ids. The current values are stored as \"[np.int64(id1), np.int64(id2), ... , np.int64(idn)]\". We first replace every character with an \"\" (which is basically removing those caracters) except the numbers using the following code:\n",
    "```\n",
    "> replace(replace(replace(replace(replace(c.available_terminals, '[', ''), ']', ''), 'np.int64(', ''), ')', ''), ' ', '') AS replaced\n",
    "```\n",
    "This will gives us \"id1,id2,...,idn\" which is named \"replaced\". Then, with the following command we can turn this string into a list of integers:\n",
    "```\n",
    "> SET c.available_terminals = [x IN split(replaced, ',') WHERE x IS NOT NULL AND x <> '' | toInteger(x)]\n",
    "```\n",
    "- split(replaced, ',') will split the string into a list of substrings using comma as a split point -> \"id1\", \"id2\", ... , \"idn\"\n",
    "- x IN ... -> iterates over the substrings.\n",
    "- WHERE x IS NOT NULL AND x <> '' -> filters out empty substrings and nulls.\n",
    "- toInteger() -> converts the remaining substring into integers.\n",
    "\n",
    "the result is a list of integer values that will be set in available_terminals property.  \n",
    "Note that we use apoc.periodic.iterate() to run the convert on all nodes. This way, we make the process safer in prevent memory overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fee2e-ce0d-4210-8bd0-68897d3b8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"MATCH (c:Customer) RETURN c\",\n",
    "        \"SET c.CUSTOMER_ID = toInteger(c.CUSTOMER_ID),\n",
    "             c.nb_terminals = toInteger(c.nb_terminals),\n",
    "             c.x_customer_id = toFloat(c.x_customer_id),\n",
    "             c.y_customer_id = toFloat(c.y_customer_id),\n",
    "             c.mean_amount = toFloat(c.mean_amount),\n",
    "             c.mean_nb_tx_per_day = toFloat(c.mean_nb_tx_per_day),\n",
    "             c.std_amount = toFloat(c.std_amount)\n",
    "        WITH c, replace(replace(replace(replace(replace(c.available_terminals, '[', ''), ']', ''), 'np.int64(', ''), ')', ''), ' ', '') AS replaced\n",
    "        SET c.available_terminals = [x IN split(replaced, ',') WHERE x IS NOT NULL AND x <> '' | toInteger(x)]\",\n",
    "        {batchSize:1000, parallel:true}\n",
    "    );\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "%time results = run_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b88c7c-9cad-46ca-bb1a-82df9acd2d3c",
   "metadata": {},
   "source": [
    "## Terminals\n",
    "For the terminal nodes, we only have three properties to convert. A TERMINAL_ID which is suppose to be an integer, and two coordinates which must be converted to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c36cef-cdb6-47a7-90e2-4a94ed033bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"MATCH (t:Terminal) RETURN t\",\n",
    "        \"SET t.TERMINAL_ID = toInteger(t.TERMINAL_ID),\n",
    "            t.x_terminal_id = toFloat(t.x_terminal_id),\n",
    "            t.y_terminal_id = toFloat(t.y_terminal_id)\",\n",
    "        {batchSize:1000, parallel:true}\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "%time results = run_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ee880-ce29-424f-8a38-1e36b6544332",
   "metadata": {},
   "source": [
    "## Transactions\n",
    "Finally, we get to the Transaction nodes. Just like the other two, the process is simple for all properties. Only for TX_DATETIME we need to have a small configuration, which is replacing the space between date and time with the letter T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6d112-ca4a-42db-aee1-2df76e28344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"MATCH (t:Transaction) RETURN t\",\n",
    "        \"SET t.TRANSACTION_ID = toInteger(t.TRANSACTION_ID),\n",
    "        t.TX_FRAUD_SCENARIO = toInteger(t.TX_FRAUD_SCENARIO),\n",
    "        t.TX_TIME_DAYS = toInteger(t.TX_TIME_DAYS),\n",
    "        t.TX_TIME_SECONDS = toInteger(t.TX_TIME_SECONDS),\n",
    "        t.TERMINAL_ID = toInteger(t.TERMINAL_ID),\n",
    "        t.CUSTOMER_ID = toInteger(t.CUSTOMER_ID),\n",
    "        t.TX_FRAUD = toInteger(t.TX_FRAUD),\n",
    "        t.TX_AMOUNT = toFloat(t.TX_AMOUNT),\n",
    "        t.TX_DATETIME = datetime(replace(t.TX_DATETIME, ' ', 'T'))\",\n",
    "        {batchSize:1000, parallel:true}\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "%time results = run_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbaec60-4389-42e9-a9be-761945a45b7c",
   "metadata": {},
   "source": [
    "the runtimes for each one are as follow:  \n",
    "- ~1s for Customer nodes.\n",
    "- Less than 1s for Terminal nodes.\n",
    "- ~7s, ~11s and ~22s for Database 1, 2 and 3, respectivelly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bef039-f65a-4cf4-98ce-caee918bc1a8",
   "metadata": {},
   "source": [
    "## Adding a new relationship\n",
    "In the end, we only need to add the new relationship that is derived from the existing two relationships. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9147d-e3be-4040-8a0e-a4c5f3468237",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    MATCH (c:Customer)-[:MADE]->(tx:Transaction)-[:OCCURRED_AT]->(t:Terminal)\n",
    "    WITH c, t,\n",
    "        count(tx) AS tx_count,\n",
    "        sum(tx.TX_AMOUNT) AS sum_amount,\n",
    "        avg(tx.TX_AMOUNT) AS mean_amount\n",
    "    MERGE (c)-[r:USED]->(t)\n",
    "    SET r.TX_COUNT = tx_count,\n",
    "        r.SUM_AMOUNT = sum_amount,\n",
    "        r.MEAN_AMOUNT = mean_amount\n",
    "\"\"\"\n",
    "\n",
    "%time results = run_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd0d8f-213f-46b7-9f66-a9fab5191307",
   "metadata": {},
   "source": [
    "<br>\n",
    "These were the final data processing before we can start with the operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c413d237-38aa-4f86-b0ac-b4a36ea4710f",
   "metadata": {},
   "source": [
    "# Operations\n",
    "Now that our database is ready, we can start with the operations.  \n",
    "Note that all the codes here are the final and optimized versions. The original codes are discussed in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0cf35a-22d2-48ee-a8b7-f8bdf9816e1e",
   "metadata": {},
   "source": [
    "## (a)\n",
    "_For each customer X, identify the customer Y (or the costumers) that share at least 3 terminals in which Y executes transactions and the spending amount of Y differs less than the 10% with respect to that of X. Return the name of X, the spending amount of X, the spending amount of the related costumer Y and the spending amount of Y._  \n",
    "<br>\n",
    "With the help of our new relationship :USED, this operation can be queried very easily. We match two customers to a mutual terminal. we make sure that the id of first customer is smaller than the second customer. This makes sure that duplicates will not be considered in the results. Then we count the number of terminals that these customers have in common and filter out the records that have less than 3 mutual terminals. Finally, we check the required condition on the spending amount of both customers.  \n",
    "<br>\n",
    "We run the query using run_query(), and also calculate the runtime using %time. We then print the number of results and the list of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754496be-47be-4f5a-841e-8fc0fe7905c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    MATCH (X:Customer)-[:USED]->(t:Terminal)<-[:USED]-(Y:Customer)\n",
    "    WHERE elementId(X) < elementId(Y)\n",
    "    WITH X, Y, count(DISTINCT t) AS shared\n",
    "    WHERE shared >= 3\n",
    "      AND abs(X.mean_amount - Y.mean_amount) < X.mean_amount * 0.1\n",
    "    RETURN X.CUSTOMER_ID AS customer_X, \n",
    "           X.mean_amount AS spending_amount_X, \n",
    "           Y.CUSTOMER_ID AS customer_Y, \n",
    "           Y.mean_amount spending_amount_Y\n",
    "    ORDER BY X.CUSTOMER_ID\n",
    "    \"\"\"\n",
    "\n",
    "%time results = run_query(query)\n",
    "print(f\"Number of records: {len(results)}\")\n",
    "for record in results:\n",
    "    print(record.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082620b3-678a-4950-90c3-693f9908d01b",
   "metadata": {},
   "source": [
    "## (b)\n",
    "_For each terminal identify the possible fraudulent transactions of the current month. The fraudulent transactions are those whose import is higher than 20% of the average import of the transactions executed on the same terminal in the previous month._  \n",
    "<br>\n",
    "We can devide this query to three parts:  \n",
    "- In part I, we find the latest month and compute orioer month boundaries.  \n",
    "- In part II, we calculate the average transaction amount on each terminal for the previous month.  \n",
    "- Finally in part III, we look for transactions which their transaction amount is more than 20% of the average treansaction amount of the previous month on the same terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb11be-4fb6-4d0c-aa99-c41313140ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "   // Part I\n",
    "MATCH (tr:Transaction)\n",
    "WITH datetime.truncate('month', max(tr.TX_DATETIME)) AS latest_month\n",
    "WITH latest_month,\n",
    "     latest_month - duration('P1M') AS prev_month,\n",
    "     latest_month + duration('P1M') AS next_month\n",
    "\n",
    "// Part II\n",
    "MATCH (prtr:Transaction)-[:OCCURRED_AT]->(t:Terminal)\n",
    "WHERE prtr.TX_DATETIME >= prev_month AND prtr.TX_DATETIME < latest_month\n",
    "WITH t, avg(prtr.TX_AMOUNT) AS avg_tr, latest_month, next_month\n",
    "\n",
    "// Part III\n",
    "MATCH (crtr:Transaction)-[:OCCURRED_AT]->(t)\n",
    "WHERE crtr.TX_DATETIME >= latest_month AND crtr.TX_DATETIME < next_month\n",
    "  AND crtr.TX_AMOUNT > avg_tr * 1.2\n",
    "\n",
    "RETURN crtr.TRANSACTION_ID AS transaction_id,\n",
    "       crtr.TX_AMOUNT AS transaction_amount,\n",
    "       t.TERMINAL_ID AS terminal_id;\n",
    "    \"\"\"\n",
    "\n",
    "%time results = run_query(query)\n",
    "print(f\"Number of records: {len(results)}\")\n",
    "for record in results:\n",
    "    print(record.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587ba5d-3fa6-49a3-8bc1-bbd3f733aba0",
   "metadata": {},
   "source": [
    "## (c)\n",
    "_Given a user u, determine the “co-customer-relationships CC of degree k”. A user u’ is a co customer of u if you can determine a chain “u1-t1-u2-t2-…tk-1-uk“ such that u1=u, uk=u’, and for  each 1<=I,j<=k, ui <> uj, and t1,..tk-1 are the terminals on which a transaction has been executed. Therefore, CCk(u)={u’| a chain exists between u and u’ of degree k}. Please, note that depending on the adopted model, the computation of CCk(u) could be quite complicated. Consider therefore at least the computation of CC3(u) (i.e. the co-costumer relationships of degree 3)_  \n",
    "<br>\n",
    "To break down the given definition:  \n",
    "- u1: the first customer.\n",
    "- uk: co-customer at degree k.\n",
    "- k: the number of customers in the chain.\n",
    "- k-1: the number of terminals in the chain.  \n",
    "\n",
    "Knowing these information, we can find the chain for the co-customer at degree 3 which is:\n",
    "start - t1 - c2 - t2 - c3\n",
    "Having that, we can write our query starting with a MATCH with the path above. Then we need to make sure that there is no duplications in the customers. Meaning all the customers in the matched chains are different than another. In the end, we return the results.  \n",
    "Notice that we used DISTINCT for the result. Because there might be more than one path between a customer and its co-customer at degree k. Since we only need to know the co-customer and not the number of paths between them, we use DISTINCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab4b0cb-a22a-42df-a55b-117cc2f7586f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        MATCH (start: Customer {CUSTOMER_ID: $startId})\n",
    "        \n",
    "        MATCH (start)-[:USED]->(:Terminal)<-[:USED]-(c2:Customer)\n",
    "              -[:USED]->(:Terminal)<-[:USED]-(c3:Customer)\n",
    "        \n",
    "        WHERE start <> c2 AND \n",
    "              start <> c3 AND c2 <> c3\n",
    "        RETURN DISTINCT c3.CUSTOMER_ID AS co_customer_degree_3\n",
    "\"\"\"\n",
    "\n",
    "# Choose your desired customer ID in integer\n",
    "startId = 50\n",
    "\n",
    "%time results = run_query(query, parameters={\"startId\": startId} )\n",
    "print(f\"Number of records: {len(results)}\")\n",
    "for record in results:\n",
    "    print(record.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160f7a8-db81-49d9-b653-d626ce8190ec",
   "metadata": {},
   "source": [
    "## (d)\n",
    "### _Extend the logical model that you have stored in the NOSQL database by introducing the following information (pay attention that this operation should be done once the NOSQL database has been already loaded with the data extracted from the datasets):_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ef5e3-2951-4a42-a1a4-586389954e8e",
   "metadata": {},
   "source": [
    "#### _i: Each transaction should be extended with:_\n",
    "\n",
    "1. _The period of the day {morning, afternoon, evening, night} in which the \n",
    "transaction has been executed._\n",
    "2. _The kind of products that have been bought through the transaction {high\n",
    "tech, food, clothing, consumable, other}._\n",
    "3. _The feeling of security expressed by the user. This is an integer value \n",
    "between 1 and 5 expressed by the user when conclude the transaction._\n",
    "\n",
    "_The values can be chosen randomly._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb4053-0a05-4b48-a0a8-c67d4947ce33",
   "metadata": {},
   "source": [
    "This operation can be done nicely with Apoc plugin.  \n",
    "First, we introduce two lists of period and product. then for every transaction, we first calculate a random float number r between 0 and 1. Then we use CASE to determine the selected period based on r. we set 3 numbers 20, 60 abd 90 to create the weights of 20, 40, 30 and 10 for 'morning', 'afternoon', 'evening' and 'night', respectively. This is added to make the distribution more realistic. For product type and security feel we make two other random number to choose between the list of products and a number in range of 1 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a178a05-d33f-408f-86bd-34d068a284cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = [\"morning\", \"afternoon\", \"evening\", \"night\"]\n",
    "product = [\"high_tech\", \"food\", \"clothing\", \"consumable\", \"other\"]\n",
    "\n",
    "query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"MATCH (t:Transaction) RETURN t\",\n",
    "        \"WITH t, rand() AS r\n",
    "        SET t.PERIOD_DAY = \n",
    "                CASE\n",
    "                    WHEN r < 0.20 THEN 'morning'\n",
    "                    WHEN r < 0.60 THEN 'afternoon'\n",
    "                    WHEN r < 0.90 THEN 'evening'\n",
    "                    ELSE 'night'\n",
    "                END,\n",
    "             t.PRODUCT_TYPE = $products[toInteger(rand() * size($products))],\n",
    "             t.SECURITY_FEEL = toInteger(rand() * 5) + 1\",\n",
    "         {batchSize:1000, parallel:true, params:{\n",
    "             periods: $periods,\n",
    "             products: $products\n",
    "         }}\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835136f-eca4-4997-8e6b-42949726de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time results = run_query(query, parameters={\"periods\": period, \"products\": product})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec71a3-4cee-4e1e-b1ce-af987559c9f6",
   "metadata": {},
   "source": [
    "### _ii: Customers that make more than three transactions  from the same terminal expressing a similar average feeling of security should be connected as “buying_friends”. Therefore also this kind of relationship should be explicitly stored in the NOSQL database and can be queried. Note, two average feelings of security are considered similar when their difference is lower than 1._\n",
    "<br>\n",
    "This operation can be easily done with the help of :USED. But unfortunately, we are missing one piece and that is the average feeling of the transactions a customer has made on a terminal. To do that, we first find all the transactions that a customer has made on one terminal, and store the average of SECURITY_FEEL property. Then we find the correspondong :USED relationship between this customer and terminal, and add the computed average feel to the relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8069fe-ab1c-46a9-b8f9-982b372a760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "        \"MATCH (c:Customer)-[:MADE]->(tx:Transaction)-[:OCCURRED_AT]->(t:Terminal)\n",
    "        WITH c, t, avg(toFloat(tx.SECURITY_FEEL)) AS avg_feel\n",
    "        RETURN c, t, avg_feel\",\n",
    "        \"MATCH (c)-[u:USED]->(t)\n",
    "        SET u.AVG_FEEL = avg_feel\",\n",
    "        {batchSize: 10000, parallel: true}\n",
    "    )\n",
    "\"\"\"\n",
    "%time results = run_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010373a2-e2ba-4232-a339-382ea7736d67",
   "metadata": {},
   "source": [
    "Now, we have everything we need to create our new relationship. to do that, we first do a MATCH between two customers and a mutual terminal using :USED relationship. Then we make sure that:\n",
    "- Customers are not the same.\n",
    "- The number of transactions each customer has made on the terminal is more than 3.\n",
    "- Both customers expressing a similar average feeling of security.\n",
    "\n",
    "If all those conditions are met, we can connect the two customers with the new relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3bb871-3fb5-4c58-b384-f6606fcbbfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    MATCH (c1:Customer)-[u1:USED]->(t:Terminal)<-[u2:USED]-(c2:Customer)\n",
    "    WHERE elementId(c1) < elementId(c2) AND\n",
    "          u1.TX_COUNT > 3 AND u2.TX_COUNT > 3 AND\n",
    "          abs(u1.AVG_FEEL - u2.AVG_FEEL) < 1\n",
    "    MERGE (c1)-[:BUYING_FRIEND]->(c2)\n",
    "\"\"\"\n",
    "\n",
    "%time results = run_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d5ae5-e28e-425b-8b11-ccd12d24d0ac",
   "metadata": {},
   "source": [
    "## (e)\n",
    "### _For each period of the day identifies the number of transactions that occurred in that period, and the average number of fraudulent transactions._\n",
    "<br>\n",
    "For the final operation, we simply group all the transactions by the period of day they have been made. We count the number of each group, count the number of fraudulent transactions and the average number of fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bbc091-0088-4552-8867-f695cc4e7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    MATCH (t:Transaction)\n",
    "    WITH t.PERIOD_DAY AS day, count(*) AS total_count, sum(t.TX_FRAUD) AS fraud_count, round(avg(t.TX_FRAUD)* 1000) / 1000 as avg_fraud\n",
    "    RETURN day, total_count, fraud_count, avg_fraud\n",
    "\"\"\"\n",
    "\n",
    "%time results = run_query(query)\n",
    "for record in results:\n",
    "    print(record.data())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
